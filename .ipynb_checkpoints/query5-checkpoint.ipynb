{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55861e25-8f3a-4662-8431-cc2ab490ed5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive'}, 'numExecutors': 8, 'executorCores': 1, 'executorMemory': '2G', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1199</td><td>application_1765289937462_1192</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1192/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1192_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1202</td><td>application_1765289937462_1194</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1194/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1194_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1204</td><td>application_1765289937462_1196</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1196/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1196_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1210</td><td>application_1765289937462_1202</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1202/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-154.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1202_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1219</td><td>application_1765289937462_1211</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1211/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1211_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1220</td><td>application_1765289937462_1212</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1212/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1212_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"numExecutors\": 8,\n",
    "    \"executorCores\": 1,\n",
    "    \"executorMemory\": \"2G\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40ce2f8-236d-4323-8626-bbf401efe6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1222</td><td>application_1765289937462_1214</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1214/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1214_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff061b397a97482586475c0c1eb85b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8534b5a825bb4f61b11fb5b72affd99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executors: 8\n",
      "Master: yarn"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, regexp_replace, sum, round, corr, desc, asc\n",
    "from sedona.spark import *\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(f\"Executors: {sc.getConf().get('spark.executor.instances')}\")\n",
    "print(f\"Master: {sc.master}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad365b5-cedf-4549-aa19-60974233b225",
   "metadata": {},
   "source": [
    "### Query 5\n",
    "Χρησιμοποιώντας ως αναφορά τα δεδομένα της απογραφής του 2020 για τον πληθυσμό και τα οικονομικά στοιχεία του 2021 για το εισόδημα ανα νοικοκυριό, να υπολογίσετε μέσα στη διετία 2020-2021\n",
    "τη συσχέτιση μέσου ετήσιου κατακεφαλήν εισοδήματος με την ετήσια μέση αναλογία εγκλημάτων\n",
    "ανά άτομο για κάθε περιοχή του Λος Άντζελες. Επαναλάβετε τον υπολογισμό εξετάζοντας μόνο τις 10\n",
    "περιοχές με το υψηλότερο και τις 10 με το χαμηλότερο ετήσιο κατακεφαλήν εισόδημα.\n",
    "\n",
    "\n",
    "Θεωρήστε ότι οι διάφορες περιοχές του Los Angeles ορίζονται από τη στήλη “COMM” του\n",
    "Census Blocks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd231dd-c3e0-46be-97b6-6ab4e43aa422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d29acbcd67348b5b845688edf96a574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_crimes = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\"\n",
    "path_cesus_blocks_fields = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020_fields.csv\"\n",
    "path_income = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\"\n",
    "\n",
    "crimes = spark.read.option(\"header\", \"true\")\\\n",
    "    .csv(path_crimes)\n",
    "\n",
    "census_fields = spark.read.option(\"header\", \"true\")\\\n",
    "    .csv(path_cesus_blocks_fields)\n",
    "\n",
    "income = spark.read.option(\"header\", \"true\")\\\n",
    "    .option(\"delimiter\", \";\")\\\n",
    "    .csv(path_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4fdb3f-9374-4acd-acba-3a2605d5e64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113c8f6a35904d32ae5582715c0541f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "geojson_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\"\n",
    "blocks_df = sedona.read.format(\"geojson\") \\\n",
    "            .option(\"multiLine\", \"true\").load(geojson_path) \\\n",
    "            .selectExpr(\"explode(features) as features\") \\\n",
    "            .select(\"features.*\")\n",
    "\n",
    "blocks = blocks_df.select( \\\n",
    "                [col(f\"properties.{col_name}\").alias(col_name) for col_name in \\\n",
    "                blocks_df.schema[\"properties\"].dataType.fieldNames()] + [\"geometry\"]) \\\n",
    "            .drop(\"properties\") \\\n",
    "            .drop(\"type\")\n",
    "\n",
    "LA_areas = blocks.filter(col(\"CITY\") == \"Los Angeles\") \\\n",
    "                .groupBy(\"COMM\") \\\n",
    "                .agg(ST_Union_Aggr(\"geometry\").alias(\"geometry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2177a62-09a8-40e1-a85c-3c3c02bd535d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60746aa07544bc78ec590a5a8e75360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[COMM#172, geometry#346], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(COMM#172, geometry#346, 1000), ENSURE_REQUIREMENTS, [plan_id=170]\n",
      "      +- HashAggregate(keys=[COMM#172, geometry#346], functions=[partial_count(1)])\n",
      "         +- Project [COMM#172, geometry#346]\n",
      "            +- RangeJoin point#361: geometry, geometry#346: geometry, WITHIN\n",
      "               :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS point#361]\n",
      "               :  +- Filter (substring(DATE OCC#31, 1, 4) IN (2020,2021) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "               :     +- FileScan csv [DATE OCC#31,LAT#55,LON#56] Batched: false, DataFilters: [substring(DATE OCC#31, 1, 4) IN (2020,2021), isnotnull( **org.apache.spark.sql.sedona_sql.expres..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DATE OCC:string,LAT:string,LON:string>\n",
      "               +- Filter isnotnull(geometry#346)\n",
      "                  +- ObjectHashAggregate(keys=[COMM#172], functions=[st_union_aggr(geometry#158, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@798e94e2, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)])\n",
      "                     +- Exchange hashpartitioning(COMM#172, 1000), ENSURE_REQUIREMENTS, [plan_id=163]\n",
      "                        +- ObjectHashAggregate(keys=[COMM#172], functions=[partial_st_union_aggr(geometry#158, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@798e94e2, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)])\n",
      "                           +- Project [features#155.properties.COMM AS COMM#172, features#155.geometry AS geometry#158]\n",
      "                              +- Filter (isnotnull(features#155.properties.CITY) AND (features#155.properties.CITY = Los Angeles))\n",
      "                                 +- Generate explode(features#147), false, [features#155]\n",
      "                                    +- Filter ((size(features#147, true) > 0) AND isnotnull(features#147))\n",
      "                                       +- FileScan geojson [features#147] Batched: false, DataFilters: [(size(features#147, true) > 0), isnotnull(features#147)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string..."
     ]
    }
   ],
   "source": [
    "# Calculate crimes per community\n",
    "crimes_numeric = crimes.withColumn(\n",
    "    \"point\",\n",
    "    ST_Point(\n",
    "        F.col(\"LON\").cast(\"double\"),\n",
    "        F.col(\"LAT\").cast(\"double\")\n",
    "    )\n",
    ").where(\n",
    "    F.substring(F.col(\"DATE OCC\"), 1, 4).isin(\"2020\", \"2021\")\n",
    ")\n",
    "\n",
    "crimes_per_area = (\n",
    "    crimes_numeric.join(\n",
    "        LA_areas,\n",
    "        ST_Contains(LA_areas[\"geometry\"], crimes_numeric[\"point\"]),\n",
    "        \"inner\"\n",
    "    )\n",
    "    .groupBy(\"COMM\", \"geometry\")\n",
    "    .agg(F.count(\"*\").alias(\"crime_count\"))\n",
    ")\n",
    "crimes_per_area.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48584e1c-d607-4129-8ddd-ed0b3bf88df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3302c84ac1f0471797cc123d6fd4d605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastHashJoin [ZCTA20#192], [Zip Code#127], Inner, BuildRight, false\n",
      "   :- Project [features#155.properties.BG20 AS BG20#164, features#155.properties.BG20FIP_CURRENT AS BG20FIP_CURRENT#165, features#155.properties.BGFIP20 AS BGFIP20#166, features#155.properties.CB20 AS CB20#167, features#155.properties.CITY AS CITY#168, features#155.properties.CITYCOMM AS CITYCOMM#169, features#155.properties.CITYCOMM_CURRENT AS CITYCOMM_CURRENT#170, features#155.properties.CITY_CURRENT AS CITY_CURRENT#171, features#155.properties.COMM AS COMM#172, features#155.properties.COMM_CURRENT AS COMM_CURRENT#173, features#155.properties.COUNTY AS COUNTY#174, features#155.properties.CT20 AS CT20#175, features#155.properties.CTCB20 AS CTCB20#176, features#155.properties.FEAT_TYPE AS FEAT_TYPE#177, features#155.properties.FIP20 AS FIP20#178, features#155.properties.FIP_CURRENT AS FIP_CURRENT#179, features#155.properties.HD22 AS HD22#180L, features#155.properties.HD_NAME AS HD_NAME#181, features#155.properties.HOUSING20 AS HOUSING20#182L, features#155.properties.OBJECTID AS OBJECTID#183L, features#155.properties.POP20 AS POP20#184L, features#155.properties.SPA22 AS SPA22#185L, features#155.properties.SPA_NAME AS SPA_NAME#186, features#155.properties.SUP21 AS SUP21#187, ... 6 more fields]\n",
      "   :  +- Filter isnotnull(features#155.properties.ZCTA20)\n",
      "   :     +- Generate explode(features#147), false, [features#155]\n",
      "   :        +- Filter ((size(features#147, true) > 0) AND isnotnull(features#147))\n",
      "   :           +- FileScan geojson [features#147] Batched: false, DataFilters: [(size(features#147, true) > 0), isnotnull(features#147)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=246]\n",
      "      +- Filter isnotnull(Zip Code#127)\n",
      "         +- FileScan csv [Zip Code#127,Community#128,Estimated Median Income#129] Batched: false, DataFilters: [isnotnull(Zip Code#127)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:string,Community:string,Estimated Median Income:string>"
     ]
    }
   ],
   "source": [
    "blocks_income = blocks.join(income, blocks[\"ZCTA20\"] == income[\"Zip Code\"])\n",
    "blocks_income.explain()\n",
    "\n",
    "blocks_total_income = blocks_income.withColumn(\n",
    "    \"cleaned_income\", \n",
    "    regexp_replace(col(\"Estimated Median Income\"), \"[$,+,-]\", \"\").cast(\"double\")\n",
    ").withColumn(\n",
    "    \"block_income\", \n",
    "    col(\"cleaned_income\") * col(\"HOUSING20\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20de1c72-9bc9-43cb-9b4d-e4a66d7e3cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1394eca455a4e559f2ce7b88c5cf19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "community_stats = blocks_total_income.groupBy(\"COMM\").agg(\n",
    "    sum(\"POP20\").alias(\"community_population\"),\n",
    "    sum(\"block_income\").alias(\"community_income\")\n",
    ").select(\"COMM\", \"community_income\", \"community_population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd0c91c-7a36-44dd-9aab-d514ad965d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f2309ff7384341bf67f1da67a48eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crimes_per_person = crimes_per_area.join(community_stats, \"COMM\") \\\n",
    "                                   .withColumn(\"crime_frequency\", \\\n",
    "                                     crimes_per_area[\"crime_count\"] / community_stats[\"community_population\"])\n",
    "# crimes_per_person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf21122-3474-49aa-82a8-95f631658f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7809d6cb304ce4bc7279374c36ba52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "community_gdp = community_stats.withColumn(\"average_income\", round(col(\"community_income\") / col(\"community_population\"), 0)).select(\"COMM\", \"average_income\")\n",
    "# community_gdp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af8aafd-6203-422c-b16d-dbc9fe4f4858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e268810e304043628c87598702582371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [COMM#172, crime_frequency#719, average_income#726]\n",
      "   +- SortMergeJoin [COMM#172], [COMM#748], Inner\n",
      "      :- Project [COMM#172, (cast(crime_count#486L as double) / cast(community_population#671L as double)) AS crime_frequency#719]\n",
      "      :  +- SortMergeJoin [COMM#172], [COMM#692], Inner\n",
      "      :     :- Sort [COMM#172 ASC NULLS FIRST], false, 0\n",
      "      :     :  +- Exchange hashpartitioning(COMM#172, 1000), ENSURE_REQUIREMENTS, [plan_id=604]\n",
      "      :     :     +- HashAggregate(keys=[COMM#172, geometry#346], functions=[count(1)])\n",
      "      :     :        +- Exchange hashpartitioning(COMM#172, geometry#346, 1000), ENSURE_REQUIREMENTS, [plan_id=602]\n",
      "      :     :           +- HashAggregate(keys=[COMM#172, geometry#346], functions=[partial_count(1)])\n",
      "      :     :              +- Project [COMM#172, geometry#346]\n",
      "      :     :                 +- RangeJoin point#361: geometry, geometry#346: geometry, WITHIN\n",
      "      :     :                    :- Project [ **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS point#361]\n",
      "      :     :                    :  +- Filter (substring(DATE OCC#31, 1, 4) IN (2020,2021) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "      :     :                    :     +- FileScan csv [DATE OCC#31,LAT#55,LON#56] Batched: false, DataFilters: [substring(DATE OCC#31, 1, 4) IN (2020,2021), isnotnull( **org.apache.spark.sql.sedona_sql.expres..., Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DATE OCC:string,LAT:string,LON:string>\n",
      "      :     :                    +- Filter isnotnull(geometry#346)\n",
      "      :     :                       +- ObjectHashAggregate(keys=[COMM#172], functions=[st_union_aggr(geometry#158, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@798e94e2, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)])\n",
      "      :     :                          +- Exchange hashpartitioning(COMM#172, 1000), ENSURE_REQUIREMENTS, [plan_id=596]\n",
      "      :     :                             +- ObjectHashAggregate(keys=[COMM#172], functions=[partial_st_union_aggr(geometry#158, org.apache.spark.sql.sedona_sql.expressions.ST_Union_Aggr@798e94e2, class[value[0]: geometry], class[value[0]: array<geometry>], true, true, 0, 0, None)])\n",
      "      :     :                                +- Project [features#155.properties.COMM AS COMM#172, features#155.geometry AS geometry#158]\n",
      "      :     :                                   +- Filter ((isnotnull(features#155.properties.CITY) AND (features#155.properties.CITY = Los Angeles)) AND isnotnull(features#155.properties.COMM))\n",
      "      :     :                                      +- Generate explode(features#147), false, [features#155]\n",
      "      :     :                                         +- Filter ((size(features#147, true) > 0) AND isnotnull(features#147))\n",
      "      :     :                                            +- FileScan geojson [features#147] Batched: false, DataFilters: [(size(features#147, true) > 0), isnotnull(features#147)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      :     +- Sort [COMM#692 ASC NULLS FIRST], false, 0\n",
      "      :        +- HashAggregate(keys=[COMM#692], functions=[sum(POP20#704L)], schema specialized)\n",
      "      :           +- Exchange hashpartitioning(COMM#692, 1000), ENSURE_REQUIREMENTS, [plan_id=555]\n",
      "      :              +- HashAggregate(keys=[COMM#692], functions=[partial_sum(POP20#704L)], schema specialized)\n",
      "      :                 +- Project [COMM#692, POP20#704L]\n",
      "      :                    +- BroadcastHashJoin [ZCTA20#712], [Zip Code#127], Inner, BuildRight, false\n",
      "      :                       :- Project [features#155.properties.COMM AS COMM#692, features#155.properties.POP20 AS POP20#704L, features#155.properties.ZCTA20 AS ZCTA20#712]\n",
      "      :                       :  +- Filter (isnotnull(features#155.properties.ZCTA20) AND isnotnull(features#155.properties.COMM))\n",
      "      :                       :     +- Generate explode(features#681), false, [features#155]\n",
      "      :                       :        +- Filter ((size(features#681, true) > 0) AND isnotnull(features#681))\n",
      "      :                       :           +- FileScan geojson [features#681] Batched: false, DataFilters: [(size(features#681, true) > 0), isnotnull(features#681)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "      :                       +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=550]\n",
      "      :                          +- Filter isnotnull(Zip Code#127)\n",
      "      :                             +- FileScan csv [Zip Code#127] Batched: false, DataFilters: [isnotnull(Zip Code#127)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:string>\n",
      "      +- Sort [COMM#748 ASC NULLS FIRST], false, 0\n",
      "         +- HashAggregate(keys=[COMM#748], functions=[sum(block_income#599), sum(POP20#760L)], schema specialized)\n",
      "            +- Exchange hashpartitioning(COMM#748, 1000), ENSURE_REQUIREMENTS, [plan_id=569]\n",
      "               +- HashAggregate(keys=[COMM#748], functions=[partial_sum(block_income#599), partial_sum(POP20#760L)], schema specialized)\n",
      "                  +- Project [COMM#748, POP20#760L, (cast(regexp_replace(Estimated Median Income#739, [$,+,-], , 1) as double) * cast(HOUSING20#758L as double)) AS block_income#599]\n",
      "                     +- BroadcastHashJoin [ZCTA20#768], [Zip Code#737], Inner, BuildRight, false\n",
      "                        :- Project [features#155.properties.COMM AS COMM#748, features#155.properties.HOUSING20 AS HOUSING20#758L, features#155.properties.POP20 AS POP20#760L, features#155.properties.ZCTA20 AS ZCTA20#768]\n",
      "                        :  +- Filter (isnotnull(features#155.properties.ZCTA20) AND isnotnull(features#155.properties.COMM))\n",
      "                        :     +- Generate explode(features#734), false, [features#155]\n",
      "                        :        +- Filter ((size(features#734, true) > 0) AND isnotnull(features#734))\n",
      "                        :           +- FileScan geojson [features#734] Batched: false, DataFilters: [(size(features#734, true) > 0), isnotnull(features#734)], Format: GEOJSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:binary,properties:struct<BG20:string,BG20FIP_CURRENT:string...\n",
      "                        +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=564]\n",
      "                           +- Filter isnotnull(Zip Code#737)\n",
      "                              +- FileScan csv [Zip Code#737,Estimated Median Income#739] Batched: false, DataFilters: [isnotnull(Zip Code#737)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_i..., PartitionFilters: [], PushedFilters: [IsNotNull(Zip Code)], ReadSchema: struct<Zip Code:string,Estimated Median Income:string>\n",
      "\n",
      "\n",
      "Computation took 31.99904179573059 sec"
     ]
    }
   ],
   "source": [
    "# Compare average income to crime rate\n",
    "import time\n",
    "final_stats = crimes_per_person.join(community_gdp, \"COMM\").select(\"COMM\", \"crime_frequency\", \"average_income\")\n",
    "final_stats.explain()\n",
    "\n",
    "start = time.time()\n",
    "final_stats.collect()\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Computation took {end - start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef14b80c-cccc-4a49-aa4d-e45b64fa7a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b5342683174e18b4a96dca9b8a6af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation for All Areas:\n",
      "+--------------------+\n",
      "|         correlation|\n",
      "+--------------------+\n",
      "|-0.18278560018011808|\n",
      "+--------------------+\n",
      "\n",
      "Correlation for Top 10 Income Areas:\n",
      "+--------------------+\n",
      "|         correlation|\n",
      "+--------------------+\n",
      "|-0.46262185688072327|\n",
      "+--------------------+\n",
      "\n",
      "Correlation for Bottom 10 Income Areas:\n",
      "+-------------------+\n",
      "|        correlation|\n",
      "+-------------------+\n",
      "|0.19599449706202743|\n",
      "+-------------------+"
     ]
    }
   ],
   "source": [
    "print(\"Correlation for All Areas:\")\n",
    "final_stats.select(corr(\"crime_frequency\", \"average_income\").alias(\"correlation\")).show()\n",
    "\n",
    "print(\"Correlation for Top 10 Income Areas:\")\n",
    "final_stats.orderBy(desc(\"average_income\")).limit(10)\\\n",
    "    .select(corr(\"crime_frequency\", \"average_income\").alias(\"correlation\")).show()\n",
    "\n",
    "print(\"Correlation for Bottom 10 Income Areas:\")\n",
    "final_stats.orderBy(asc(\"average_income\")).limit(10)\\\n",
    "    .select(corr(\"crime_frequency\", \"average_income\").alias(\"correlation\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
