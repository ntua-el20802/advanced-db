{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d505021-005d-44ee-a372-93d2962419b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>397</td><td>application_1765289937462_0393</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0393/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-103.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0393_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2489034f2f6c4bdab40cbe9ba88056bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672568a2072d440b884bdfae74059634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "name 'lower' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 23, in run_benchmark\n",
      "  File \"<stdin>\", line 52, in native_df_query\n",
      "NameError: name 'lower' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixed benchmarking approach\n",
    "\n",
    "crimes_old_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\"\n",
    "crimes_new_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\"\n",
    "\n",
    "crimes_old_df = spark.read.csv(crimes_old_path, header=True, inferSchema=True)\n",
    "crimes_new_df = spark.read.csv(crimes_new_path, header=True, inferSchema=True)\n",
    "\n",
    "times = {}\n",
    "results = {}\n",
    "\n",
    "# Helper function to run benchmark multiple times\n",
    "def run_benchmark(name, func, warmup=1, runs=3):\n",
    "    \"\"\"Run benchmark with warmup and multiple iterations\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Benchmarking: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Warmup runs\n",
    "    for i in range(warmup):\n",
    "        print(f\"Warmup run {i+1}/{warmup}...\")\n",
    "        spark.catalog.clearCache()\n",
    "        func()\n",
    "    \n",
    "    # Actual benchmark runs\n",
    "    run_times = []\n",
    "    for i in range(runs):\n",
    "        print(f\"Benchmark run {i+1}/{runs}...\")\n",
    "        spark.catalog.clearCache()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result = func()\n",
    "        end_time = time.time()\n",
    "        \n",
    "        elapsed = end_time - start_time\n",
    "        run_times.append(elapsed)\n",
    "        print(f\"  Time: {elapsed:.4f} sec\")\n",
    "    \n",
    "    avg_time = sum(run_times) / len(run_times)\n",
    "    print(f\"\\nAverage time: {avg_time:.4f} sec\")\n",
    "    print(f\"Min time: {min(run_times):.4f} sec\")\n",
    "    print(f\"Max time: {max(run_times):.4f} sec\")\n",
    "    \n",
    "    return result, avg_time\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Native DataFrame (without UDF)\n",
    "# =============================================================================\n",
    "def native_df_query():\n",
    "    crimes_df = crimes_old_df.unionByName(crimes_new_df)\n",
    "    assaults_df = crimes_df.filter(\n",
    "        lower(col(\"Crm Cd Desc\")).contains(\"aggravated assault\")\n",
    "    )\n",
    "    \n",
    "    assaults_grouped_df = assaults_df.withColumn(\n",
    "        \"Age_Group\",\n",
    "        when(col(\"Vict Age\") < 18, \"Children\")\n",
    "        .when((col(\"Vict Age\") >= 18) & (col(\"Vict Age\") <= 24), \"Young Adults\")\n",
    "        .when((col(\"Vict Age\") >= 25) & (col(\"Vict Age\") <= 64), \"Adults\")\n",
    "        .when(col(\"Vict Age\") > 64, \"Elderly\")\n",
    "    )\n",
    "    \n",
    "    result = assaults_grouped_df \\\n",
    "        .filter(col(\"Age_Group\").isNotNull()) \\\n",
    "        .groupBy(\"Age_Group\") \\\n",
    "        .count() \\\n",
    "        .orderBy(desc(\"count\"))\n",
    "    \n",
    "    # IMPORTANT: Collect to fully materialize results\n",
    "    return result.collect()\n",
    "\n",
    "results['native_df'], times['native_df'] = run_benchmark(\n",
    "    \"Native DataFrame\", \n",
    "    native_df_query,\n",
    "    warmup=1,\n",
    "    runs=3\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. DataFrame with UDF\n",
    "# =============================================================================\n",
    "def age_group(age):\n",
    "    if age is None:\n",
    "        return None\n",
    "    if age < 18:\n",
    "        return \"Children\"\n",
    "    elif 18 <= age <= 24:\n",
    "        return \"Young Adults\"\n",
    "    elif 25 <= age <= 64:\n",
    "        return \"Adults\"\n",
    "    else:\n",
    "        return \"Elderly\"\n",
    "\n",
    "age_group_udf = udf(age_group, StringType())\n",
    "\n",
    "def udf_query():\n",
    "    crimes_df_udf = crimes_old_df.unionByName(crimes_new_df)\n",
    "    assaults_df_udf = crimes_df_udf.filter(\n",
    "        lower(col(\"Crm Cd Desc\")).contains(\"aggravated assault\")\n",
    "    )\n",
    "    \n",
    "    udf_df = assaults_df_udf.withColumn(\n",
    "        \"Age_Group\", \n",
    "        age_group_udf(col(\"Vict Age\"))\n",
    "    )\n",
    "    \n",
    "    result_udf = udf_df \\\n",
    "        .filter(col(\"Age_Group\").isNotNull()) \\\n",
    "        .groupBy(\"Age_Group\") \\\n",
    "        .count() \\\n",
    "        .orderBy(desc(\"count\"))\n",
    "    \n",
    "    return result_udf.collect()\n",
    "\n",
    "results['udf'], times['udf'] = run_benchmark(\n",
    "    \"DataFrame with UDF\",\n",
    "    udf_query,\n",
    "    warmup=1,\n",
    "    runs=3\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. RDD\n",
    "# =============================================================================\n",
    "def map_to_age_groups(row):\n",
    "    age = row['Vict Age']\n",
    "    if age is None:\n",
    "        return None\n",
    "    if age < 18:\n",
    "        age_group = \"Children\"\n",
    "    elif 18 <= age <= 24:\n",
    "        age_group = \"Young Adults\"\n",
    "    elif 25 <= age <= 64:\n",
    "        age_group = \"Adults\"\n",
    "    else:\n",
    "        age_group = \"Elderly\"\n",
    "    return (age_group, 1)\n",
    "\n",
    "def rdd_query():\n",
    "    crimes_old_rdd = crimes_old_df.rdd\n",
    "    crimes_new_rdd = crimes_new_df.rdd\n",
    "    crimes_rdd = crimes_old_rdd.union(crimes_new_rdd)\n",
    "    \n",
    "    assaults_rdd = crimes_rdd.filter(\n",
    "        lambda row: row['Crm Cd Desc'] and \n",
    "                   'aggravated assault' in row['Crm Cd Desc'].lower()\n",
    "    )\n",
    "    \n",
    "    counts_rdd = assaults_rdd \\\n",
    "        .map(map_to_age_groups) \\\n",
    "        .filter(lambda x: x is not None) \\\n",
    "        .reduceByKey(lambda a, b: a + b)\n",
    "    \n",
    "    sorted_rdd = counts_rdd.map(lambda x: (x[1], x[0])) \\\n",
    "                           .sortByKey(ascending=False)\n",
    "    \n",
    "    result_rdd = sorted_rdd.map(lambda x: (x[1], x[0]))\n",
    "    \n",
    "    return result_rdd.collect()\n",
    "\n",
    "results['rdd'], times['rdd'] = run_benchmark(\n",
    "    \"RDD\",\n",
    "    rdd_query,\n",
    "    warmup=1,\n",
    "    runs=3\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Verification and Summary\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESULTS VERIFICATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Convert results to sorted dictionaries for comparison\n",
    "def to_dict(result_list):\n",
    "    return {row['Age_Group'] if isinstance(row, dict) else row[0]: \n",
    "            row['count'] if isinstance(row, dict) else row[1] \n",
    "            for row in result_list}\n",
    "\n",
    "native_dict = to_dict(results['native_df'])\n",
    "udf_dict = to_dict(results['udf'])\n",
    "rdd_dict = dict(results['rdd'])\n",
    "\n",
    "print(\"\\nNative DF:\", native_dict)\n",
    "print(\"UDF DF:   \", udf_dict)\n",
    "print(\"RDD:      \", rdd_dict)\n",
    "\n",
    "# Check if results match\n",
    "if native_dict == udf_dict == rdd_dict:\n",
    "    print(\"\\n✓ All results match!\")\n",
    "else:\n",
    "    print(\"\\n✗ WARNING: Results do not match!\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Native DataFrame: {times['native_df']:.4f} sec\")\n",
    "print(f\"DataFrame + UDF:  {times['udf']:.4f} sec\")\n",
    "print(f\"RDD:              {times['rdd']:.4f} sec\")\n",
    "\n",
    "# Calculate speedup\n",
    "baseline = times['native_df']\n",
    "print(f\"\\nSpeedup vs Native DataFrame:\")\n",
    "print(f\"  UDF: {baseline/times['udf']:.2f}x\")\n",
    "print(f\"  RDD: {baseline/times['rdd']:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
